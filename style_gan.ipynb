{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of style_gan.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/present/blob/master/youtube/style_gan.ipynb","timestamp":1594794596321}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pIabOSPhYgTD","colab_type":"text"},"source":["# Generating High Rez GAN Faces with Google CoLab\n","\n","This notebook demonstrates how to run [NVidia StyleGAN](https://github.com/NVlabs/stylegan) inside of a Google CoLab notebook.  I suggest you use this to generate GAN faces from a pretrained model.  If you try to train your own, you will run into compute limitations of Google CoLab.\n","\n","This code is running on a GPU instance.  GPU is assumed.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"kv7PBBU7kOkD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594793621417,"user_tz":-330,"elapsed":25763,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"3df07583-cd83-4a1d-b0cd-55609df3a6ac"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zX4LsOo_YstE","colab_type":"text"},"source":["Next, clone Stylegan from GitHub."]},{"cell_type":"code","metadata":{"id":"JjDcs9Wvhk_6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1594793664803,"user_tz":-330,"elapsed":6826,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"8459f1b6-4e4d-4ee8-e79d-4a3afbe3389a"},"source":["!git clone https://github.com/NVlabs/stylegan.git"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Cloning into 'stylegan'...\n","remote: Enumerating objects: 83, done.\u001b[K\n","remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n","Unpacking objects: 100% (83/83), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FhGqVIl8Y1m1","colab_type":"text"},"source":["Verify that Stylegan has been cloned."]},{"cell_type":"code","metadata":{"id":"4TQMXLBNjoV5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1594793680661,"user_tz":-330,"elapsed":5414,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"bdb1681b-32e2-45f4-f2fa-7a1d6ef03243"},"source":["!ls /content/stylegan/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["config.py\t     LICENSE.txt\t    run_metrics.py\n","dataset_tool.py      metrics\t\t    stylegan-teaser.png\n","dnnlib\t\t     pretrained_example.py  training\n","generate_figures.py  README.md\t\t    train.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zARjPp4rY6vc","colab_type":"text"},"source":["Add the Stylegan folder to Python so that you can import it."]},{"cell_type":"code","metadata":{"id":"DaFXI2RMhmly","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594793738349,"user_tz":-330,"elapsed":1482,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"1bf496c4-f712-48c5-ce54-ed3dfae60609"},"source":["import sys\n","sys.path.insert(0, \"/content/stylegan\")\n","\n","import dnnlib\n","%tensorflow_version 1.x"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JxmjqpxdZFkj","colab_type":"text"},"source":["The code below is baed on code from NVidia.  This actually generates your images."]},{"cell_type":"code","metadata":{"id":"MfN_qgXVi2PU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594794183964,"user_tz":-330,"elapsed":19633,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"4ec55ada-47a4-4180-a4db-d1208ea2acab"},"source":["# Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n","#\n","# This work is licensed under the Creative Commons Attribution-NonCommercial\n","# 4.0 International License. To view a copy of this license, visit\n","# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n","# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n","\n","\"\"\"Minimal script for generating an image using pre-trained StyleGAN generator.\"\"\"\n","\n","import os\n","import pickle\n","import numpy as np\n","import PIL.Image\n","import dnnlib\n","import dnnlib.tflib as tflib\n","import config\n","\n","def main():\n","    # Initialize TensorFlow.\n","    tflib.init_tf()\n","\n","    # Load pre-trained network.\n","    url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # karras2019stylegan-ffhq-1024x1024.pkl\n","    with dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n","        _G, _D, Gs = pickle.load(f)\n","        # _G = Instantaneous snapshot of the generator. Mainly useful for resuming a previous training run.\n","        # _D = Instantaneous snapshot of the discriminator. Mainly useful for resuming a previous training run.\n","        # Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.\n","\n","    # Print network details.\n","    Gs.print_layers()\n","\n","    # Pick latent vector.\n","    rnd = np.random.RandomState(123)\n","    \n","\n","    latents = rnd.randn(1, Gs.input_shape[1])\n","\n","    # Generate image.\n","    fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n","    images = Gs.run(latents, None, truncation_psi=0.7, randomize_noise=True, output_transform=fmt)\n","\n","    # Save image.\n","    os.makedirs(config.result_dir, exist_ok=True)\n","    png_filename = os.path.join(config.result_dir, f'/content/drive/My Drive/images/example2.png')\n","    PIL.Image.fromarray(images[0], 'RGB').save(png_filename)\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","Gs                              Params    OutputShape          WeightShape     \n","---                             ---       ---                  ---             \n","latents_in                      -         (?, 512)             -               \n","labels_in                       -         (?, 0)               -               \n","lod                             -         ()                   -               \n","dlatent_avg                     -         (512,)               -               \n","G_mapping/latents_in            -         (?, 512)             -               \n","G_mapping/labels_in             -         (?, 0)               -               \n","G_mapping/PixelNorm             -         (?, 512)             -               \n","G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense2                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense3                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense4                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense5                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense6                262656    (?, 512)             (512, 512)      \n","G_mapping/Dense7                262656    (?, 512)             (512, 512)      \n","G_mapping/Broadcast             -         (?, 18, 512)         -               \n","G_mapping/dlatents_out          -         (?, 18, 512)         -               \n","Truncation                      -         (?, 18, 512)         -               \n","G_synthesis/dlatents_in         -         (?, 18, 512)         -               \n","G_synthesis/4x4/Const           534528    (?, 512, 4, 4)       (512,)          \n","G_synthesis/4x4/Conv            2885632   (?, 512, 4, 4)       (3, 3, 512, 512)\n","G_synthesis/ToRGB_lod8          1539      (?, 3, 4, 4)         (1, 1, 512, 3)  \n","G_synthesis/8x8/Conv0_up        2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1           2885632   (?, 512, 8, 8)       (3, 3, 512, 512)\n","G_synthesis/ToRGB_lod7          1539      (?, 3, 8, 8)         (1, 1, 512, 3)  \n","G_synthesis/Upscale2D           -         (?, 3, 8, 8)         -               \n","G_synthesis/Grow_lod7           -         (?, 3, 8, 8)         -               \n","G_synthesis/16x16/Conv0_up      2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1         2885632   (?, 512, 16, 16)     (3, 3, 512, 512)\n","G_synthesis/ToRGB_lod6          1539      (?, 3, 16, 16)       (1, 1, 512, 3)  \n","G_synthesis/Upscale2D_1         -         (?, 3, 16, 16)       -               \n","G_synthesis/Grow_lod6           -         (?, 3, 16, 16)       -               \n","G_synthesis/32x32/Conv0_up      2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1         2885632   (?, 512, 32, 32)     (3, 3, 512, 512)\n","G_synthesis/ToRGB_lod5          1539      (?, 3, 32, 32)       (1, 1, 512, 3)  \n","G_synthesis/Upscale2D_2         -         (?, 3, 32, 32)       -               \n","G_synthesis/Grow_lod5           -         (?, 3, 32, 32)       -               \n","G_synthesis/64x64/Conv0_up      1442816   (?, 256, 64, 64)     (3, 3, 512, 256)\n","G_synthesis/64x64/Conv1         852992    (?, 256, 64, 64)     (3, 3, 256, 256)\n","G_synthesis/ToRGB_lod4          771       (?, 3, 64, 64)       (1, 1, 256, 3)  \n","G_synthesis/Upscale2D_3         -         (?, 3, 64, 64)       -               \n","G_synthesis/Grow_lod4           -         (?, 3, 64, 64)       -               \n","G_synthesis/128x128/Conv0_up    426496    (?, 128, 128, 128)   (3, 3, 256, 128)\n","G_synthesis/128x128/Conv1       279040    (?, 128, 128, 128)   (3, 3, 128, 128)\n","G_synthesis/ToRGB_lod3          387       (?, 3, 128, 128)     (1, 1, 128, 3)  \n","G_synthesis/Upscale2D_4         -         (?, 3, 128, 128)     -               \n","G_synthesis/Grow_lod3           -         (?, 3, 128, 128)     -               \n","G_synthesis/256x256/Conv0_up    139520    (?, 64, 256, 256)    (3, 3, 128, 64) \n","G_synthesis/256x256/Conv1       102656    (?, 64, 256, 256)    (3, 3, 64, 64)  \n","G_synthesis/ToRGB_lod2          195       (?, 3, 256, 256)     (1, 1, 64, 3)   \n","G_synthesis/Upscale2D_5         -         (?, 3, 256, 256)     -               \n","G_synthesis/Grow_lod2           -         (?, 3, 256, 256)     -               \n","G_synthesis/512x512/Conv0_up    51328     (?, 32, 512, 512)    (3, 3, 64, 32)  \n","G_synthesis/512x512/Conv1       42112     (?, 32, 512, 512)    (3, 3, 32, 32)  \n","G_synthesis/ToRGB_lod1          99        (?, 3, 512, 512)     (1, 1, 32, 3)   \n","G_synthesis/Upscale2D_6         -         (?, 3, 512, 512)     -               \n","G_synthesis/Grow_lod1           -         (?, 3, 512, 512)     -               \n","G_synthesis/1024x1024/Conv0_up  21056     (?, 16, 1024, 1024)  (3, 3, 32, 16)  \n","G_synthesis/1024x1024/Conv1     18752     (?, 16, 1024, 1024)  (3, 3, 16, 16)  \n","G_synthesis/ToRGB_lod0          51        (?, 3, 1024, 1024)   (1, 1, 16, 3)   \n","G_synthesis/Upscale2D_7         -         (?, 3, 1024, 1024)   -               \n","G_synthesis/Grow_lod0           -         (?, 3, 1024, 1024)   -               \n","G_synthesis/images_out          -         (?, 3, 1024, 1024)   -               \n","G_synthesis/lod                 -         ()                   -               \n","G_synthesis/noise0              -         (1, 1, 4, 4)         -               \n","G_synthesis/noise1              -         (1, 1, 4, 4)         -               \n","G_synthesis/noise2              -         (1, 1, 8, 8)         -               \n","G_synthesis/noise3              -         (1, 1, 8, 8)         -               \n","G_synthesis/noise4              -         (1, 1, 16, 16)       -               \n","G_synthesis/noise5              -         (1, 1, 16, 16)       -               \n","G_synthesis/noise6              -         (1, 1, 32, 32)       -               \n","G_synthesis/noise7              -         (1, 1, 32, 32)       -               \n","G_synthesis/noise8              -         (1, 1, 64, 64)       -               \n","G_synthesis/noise9              -         (1, 1, 64, 64)       -               \n","G_synthesis/noise10             -         (1, 1, 128, 128)     -               \n","G_synthesis/noise11             -         (1, 1, 128, 128)     -               \n","G_synthesis/noise12             -         (1, 1, 256, 256)     -               \n","G_synthesis/noise13             -         (1, 1, 256, 256)     -               \n","G_synthesis/noise14             -         (1, 1, 512, 512)     -               \n","G_synthesis/noise15             -         (1, 1, 512, 512)     -               \n","G_synthesis/noise16             -         (1, 1, 1024, 1024)   -               \n","G_synthesis/noise17             -         (1, 1, 1024, 1024)   -               \n","images_out                      -         (?, 3, 1024, 1024)   -               \n","---                             ---       ---                  ---             \n","Total                           26219627                                       \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tzqJGX1Gj_fn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1594794256640,"user_tz":-330,"elapsed":5692,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"0b688daf-6ff9-4c2a-e7fd-e7f11dd86fe1"},"source":["!ls /content/drive/My\\ Drive/"],"execution_count":9,"outputs":[{"output_type":"stream","text":[" 12017009001040_CSE3B_1.pdf  'Getting started.pdf'\n"," Classroom\t\t      images\n"," cod.png\t\t      Java\n","'Colab Notebooks'\t     'karras2019stylegan-ffhq-1024x1024 (1).pkl'\n"," COVID19\t\t      karras2019stylegan-ffhq-1024x1024.pkl\n"," CSE3B_01.pdf\t\t      SadikaSayma_20101131.ipynb\n","'CSE3B_1 (1).pdf'\t      shape_predictor_68_face_landmarks.dat\n"," CSE3B_1.pdf\t\t     'Untitled folder'\n"," CSE3B_1.pptx\t\t      updated_members.xlsx\n"," Data.csv\t\t     'VHDLFLIPFLOP (1).gdoc'\n","'ECO (1).rar'\t\t      VHDLFLIPFLOP.docx\n"," ECO.rar\t\t      VHDLFLIPFLOP.gdoc\n"],"name":"stdout"}]}]}